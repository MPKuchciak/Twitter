{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching up to 10 tweets from @bbudka ...\n",
      "Saved 10 tweets to tweets_data\\bbudka_tweets.json.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import os \n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAMDEwgEAAAAAnWYAoWu%2BVlsQCt8cZhQYdfxB4js%3DJQE728TPFzLegBT7Tbzuke1zfk1Byx1ZH7OmeUI52NGhrk6Emu\"  # Replace with your Bearer Token\n",
    "\n",
    "# List of public usernames to fetch\n",
    "POLITICIANS = [\"bbudka\"]  # Add more usernames as needed #elonmusk #donaldtusk #SlawomirMentzen\n",
    "\n",
    "# Maximum tweets to fetch (up to 3,200 most recent tweets)\n",
    "MAX_TWEETS = 10#200 go for less maybe?\n",
    "\n",
    "# Date range for fetching tweets (ISO8601 format)\n",
    "START_TIME = \"2022-01-01T00:00:00Z\"\n",
    "END_TIME = \"2024-12-31T23:59:59Z\"\n",
    "\n",
    "# Whether to exclude retweets and replies\n",
    "EXCLUDE_RETWEETS = True\n",
    "EXCLUDE_REPLIES = True\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Authentication\n",
    "# -----------------------------------------------------------------------------\n",
    "def authenticate_app_only(bearer_token):\n",
    "    \"\"\"\n",
    "    Authenticate with the Twitter API using Tweepy (App-Only Auth).\n",
    "    \"\"\"\n",
    "    return tweepy.Client(\n",
    "        bearer_token=bearer_token,\n",
    "        wait_on_rate_limit=True\n",
    "    )\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Categorize Tweets\n",
    "# -----------------------------------------------------------------------------\n",
    "def categorize_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Categorize the tweet as 'Original', 'Reply', 'Retweet', or 'Quote'.\n",
    "    \"\"\"\n",
    "    if \"referenced_tweets\" in tweet:\n",
    "        for ref in tweet[\"referenced_tweets\"]:\n",
    "            if ref[\"type\"] == \"retweeted\":\n",
    "                return \"Retweet\"\n",
    "            elif ref[\"type\"] == \"replied_to\":\n",
    "                return \"Reply\"\n",
    "            elif ref[\"type\"] == \"quoted\":\n",
    "                return \"Quote\"\n",
    "    elif \"in_reply_to_user_id\" in tweet and tweet[\"in_reply_to_user_id\"] is not None:\n",
    "        return \"Reply\"\n",
    "    return \"Original\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Fetch Tweets with All Possible Fields\n",
    "# -----------------------------------------------------------------------------\n",
    "def fetch_all_tweet_fields(client, username, max_tweets, start_time, end_time, exclude_retweets=True, exclude_replies=True):\n",
    "    \"\"\"\n",
    "    Fetch a user's timeline with all possible fields and categorize tweets.\n",
    "    \"\"\"\n",
    "    # A) Get the user's ID\n",
    "    user_resp = client.get_user(username=username)\n",
    "    if not user_resp or not user_resp.data:\n",
    "        print(f\"ERROR: Could not find user '{username}'.\")\n",
    "        return []\n",
    "    user_id = user_resp.data.id\n",
    "\n",
    "    # B) Build exclude parameters\n",
    "    exclude_params = []\n",
    "    if exclude_retweets:\n",
    "        exclude_params.append(\"retweets\")\n",
    "    if exclude_replies:\n",
    "        exclude_params.append(\"replies\")\n",
    "\n",
    "    # C) Define fields and expansions\n",
    "    tweet_fields = [\n",
    "        \"attachments\", \"author_id\", \"context_annotations\", \"conversation_id\", \"created_at\",\n",
    "        \"edit_controls\", \"entities\", \"geo\", \"id\", \"in_reply_to_user_id\", \"lang\",\n",
    "        \"possibly_sensitive\", \"public_metrics\", \"referenced_tweets\", \"reply_settings\",\n",
    "        \"source\", \"text\", \"withheld\"\n",
    "    ]\n",
    "    user_fields = [\n",
    "        \"created_at\", \"description\", \"entities\", \"id\", \"location\", \"name\", \"pinned_tweet_id\",\n",
    "        \"profile_image_url\", \"protected\", \"public_metrics\", \"url\", \"username\", \"verified\", \"withheld\"\n",
    "    ]\n",
    "    media_fields = [\n",
    "        \"duration_ms\", \"height\", \"media_key\", \"preview_image_url\", \"type\", \"url\",\n",
    "        \"width\", \"public_metrics\", \"alt_text\", \"variants\"\n",
    "    ]\n",
    "    place_fields = [\n",
    "        \"contained_within\", \"country\", \"country_code\", \"full_name\", \"geo\", \"id\", \"name\", \"place_type\"\n",
    "    ]\n",
    "    poll_fields = [\n",
    "        \"duration_minutes\", \"end_datetime\", \"id\", \"options\", \"voting_status\"\n",
    "    ]\n",
    "    expansions = [\n",
    "        \"attachments.poll_ids\", \"attachments.media_keys\", \"author_id\", \"in_reply_to_user_id\",\n",
    "        \"referenced_tweets.id\", \"referenced_tweets.id.author_id\", \"entities.mentions.username\",\n",
    "        \"geo.place_id\"\n",
    "    ]\n",
    "\n",
    "    # D) Fetch tweets using Tweepy Paginator\n",
    "    tweets = []\n",
    "    paginator = tweepy.Paginator(\n",
    "        client.get_users_tweets,\n",
    "        id=user_id,\n",
    "        tweet_fields=tweet_fields,\n",
    "        user_fields=user_fields,\n",
    "        media_fields=media_fields,\n",
    "        place_fields=place_fields,\n",
    "        poll_fields=poll_fields,\n",
    "        expansions=expansions,\n",
    "        exclude=exclude_params if exclude_params else None,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        max_results=100  # Max per request\n",
    "    )\n",
    "\n",
    "    for tweet in paginator.flatten(limit=max_tweets):\n",
    "        tweet_data = tweet.data\n",
    "        tweet_data[\"category\"] = categorize_tweet(tweet_data)  # Add categorization\n",
    "        tweets.append(tweet_data)\n",
    "    return tweets\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Save Tweets to JSON\n",
    "# -----------------------------------------------------------------------------\n",
    "def save_tweets_to_json(tweets, filename, folder=\"tweets_data\"):\n",
    "    \"\"\"\n",
    "    Save tweets to a JSON file in the specified folder.\n",
    "    \"\"\"\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder, filename)\n",
    "\n",
    "    # Save the JSON file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tweets, f, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "    print(f\"Saved {len(tweets)} tweets to {file_path}.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Main Function\n",
    "# -----------------------------------------------------------------------------\n",
    "def main():\n",
    "    # Authenticate\n",
    "    client = authenticate_app_only(BEARER_TOKEN)\n",
    "\n",
    "    # Loop through each username and fetch tweets\n",
    "    for username in POLITICIANS:\n",
    "        print(f\"Fetching up to {MAX_TWEETS} tweets from @{username} ...\")\n",
    "        tweets = fetch_all_tweet_fields(\n",
    "            client=client,\n",
    "            username=username,\n",
    "            max_tweets=MAX_TWEETS,\n",
    "            start_time=START_TIME,\n",
    "            end_time=END_TIME,\n",
    "            exclude_retweets=EXCLUDE_RETWEETS,\n",
    "            exclude_replies=EXCLUDE_REPLIES\n",
    "        )\n",
    "        # Save tweets to a file named after the username\n",
    "        filename = f\"{username}_tweets.json\"\n",
    "        save_tweets_to_json(tweets, filename)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run the Script\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exclude parameter in the API (exclude=[\"retweets\", \"replies\"]) prevents the API from sending retweets and replies in the first place. This saves API bandwidth and reduces unnecessary data processing on your side.\n",
    "Unfortunately, Twitter's API does not have a parameter to exclude quote tweets during the initial request. Filtering out quote tweets has to be done manually after you receive the data, which means tokens are already consumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

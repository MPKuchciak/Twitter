{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tweepy\n",
      "  Downloading tweepy-4.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tweepy) (2.32.2)\n",
      "Collecting requests-oauthlib<2,>=1.2.0 (from tweepy)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n",
      "Downloading tweepy-4.14.0-py3-none-any.whl (98 kB)\n",
      "   ---------------------------------------- 0.0/98.5 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/98.5 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 41.0/98.5 kB 495.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 98.5/98.5 kB 939.1 kB/s eta 0:00:00\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-1.3.1 tweepy-4.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAANwjwwEAAAAA8G5%2FsbtLy6o7xIgRYzpn8o4HhJQ%3DYkBemysNouBcEpyh71Ap7GhcCeli5jlgQICQ4oXTn2p7ROvSo6\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.client.Client at 0x20dcb7cee70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Arlukowicz id skołować"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching tweets: 429 Too Many Requests\n",
      "Too Many Requests\n"
     ]
    }
   ],
   "source": [
    "# Define user ID, date range, and max results\n",
    "user_id = \"375146901\"  # Replace with the actual user ID you want\n",
    "max_results = 5  # Set the max number of tweets you want\n",
    "start_time = \"2024-10-31T00:00:00Z\"  # Define the start time in RFC 3339 format\n",
    "end_time = \"2024-11-07T00:00:00Z\"  # Define the end time in RFC 3339 format\n",
    "\n",
    "# Fetch tweets\n",
    "try:\n",
    "    response = client.get_users_tweets(\n",
    "        id=user_id,\n",
    "        max_results=max_results,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        tweet_fields=[\"created_at\", \"text\"]\n",
    "    )\n",
    "\n",
    "    # Display the tweets\n",
    "    for tweet in response.data:\n",
    "        print(f\"{tweet.created_at} - {tweet.text}\")\n",
    "\n",
    "except tweepy.TweepyException as e:\n",
    "    print(f\"Error fetching tweets: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tweet id=1852701257267318972 text='Harris or Trump? Some claim that the future of Europe depends on the American elections, while it depends first and foremost on us. On condition Europe finally grows up and believes in its own strength. Whatever the outcome, the era of geopolitical outsourcing is over.'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST NUMBER 2 \n",
    "import tweepy\n",
    "import datetime\n",
    "\n",
    "# Replace with your own bearer token\n",
    "#BEARER_TOKEN = \"your_bearer_token_here\"\n",
    "\n",
    "# Initialize the client\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "# Parameters\n",
    "user_id = \"375146901\"  # Replace with the desired user's ID\n",
    "max_results = 100  # Number of tweets per page (between 5 and 100)\n",
    "start_time = \"2023-10-29T00:00:00Z\"  # Replace with your start date/time\n",
    "end_time = \"2023-11-07T00:00:00Z\"    # Replace with your end date/time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'375146901'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch tweets with pagination\n",
    "response = client.get_users_tweets(\n",
    "    id=user_id,  # Note that 'id' is the parameter name in this function\n",
    "    max_results=max_results,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    tweet_fields=[\"created_at\", \"text\", \"id\", \"author_id\", \"public_metrics\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 1721613967498387886\n",
      "Created at: 2023-11-06 19:42:10+00:00\n",
      "Text: Ich już nie ma. https://t.co/PWfyzKkZyA\n",
      "Author ID: 375146901\n",
      "Public Metrics: {'retweet_count': 2341, 'reply_count': 1716, 'like_count': 12439, 'quote_count': 249, 'bookmark_count': 69, 'impression_count': 609558}\n",
      "------------------------------\n",
      "Tweet ID: 1720892929512988968\n",
      "Created at: 2023-11-04 19:57:01+00:00\n",
      "Text: Nie dzwoń już więcej, Mateusz. Mamy komplet ministrów.\n",
      "Author ID: 375146901\n",
      "Public Metrics: {'retweet_count': 3759, 'reply_count': 3439, 'like_count': 37986, 'quote_count': 544, 'bookmark_count': 169, 'impression_count': 1647648}\n",
      "------------------------------\n",
      "Tweet ID: 1719378456910221417\n",
      "Created at: 2023-10-31 15:39:03+00:00\n",
      "Text: Meldunek od serca. https://t.co/Lrrk7T3KAC\n",
      "Author ID: 375146901\n",
      "Public Metrics: {'retweet_count': 2660, 'reply_count': 2375, 'like_count': 12099, 'quote_count': 336, 'bookmark_count': 59, 'impression_count': 1173414}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the fetched tweets\n",
    "for tweet in response.data:\n",
    "    print(f\"Tweet ID: {tweet.id}\")\n",
    "    print(f\"Created at: {tweet.created_at}\")\n",
    "    print(f\"Text: {tweet.text}\")\n",
    "    print(f\"Author ID: {tweet.author_id}\")\n",
    "    print(f\"Public Metrics: {tweet.public_metrics}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tweet ID: 1721613967498387886\n",
    "Created at: 2023-11-06 19:42:10+00:00\n",
    "Text: Ich już nie ma. https://t.co/PWfyzKkZyA\n",
    "Author ID: 375146901\n",
    "Public Metrics: {'retweet_count': 2341, 'reply_count': 1716, 'like_count': 12439, 'quote_count': 249, 'bookmark_count': 69, 'impression_count': 609558}\n",
    "------------------------------\n",
    "Tweet ID: 1720892929512988968\n",
    "Created at: 2023-11-04 19:57:01+00:00\n",
    "Text: Nie dzwoń już więcej, Mateusz. Mamy komplet ministrów.\n",
    "Author ID: 375146901\n",
    "Public Metrics: {'retweet_count': 3759, 'reply_count': 3439, 'like_count': 37986, 'quote_count': 544, 'bookmark_count': 169, 'impression_count': 1647648}\n",
    "------------------------------\n",
    "Tweet ID: 1719378456910221417\n",
    "Created at: 2023-10-31 15:39:03+00:00\n",
    "Text: Meldunek od serca. https://t.co/Lrrk7T3KAC\n",
    "Author ID: 375146901\n",
    "Public Metrics: {'retweet_count': 2660, 'reply_count': 2375, 'like_count': 12099, 'quote_count': 336, 'bookmark_count': 59, 'impression_count': 1173414}\n",
    "------------------------------\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429 Too Many Requests\n",
      "Too Many Requests\n",
      "Error saving tweets: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tweepy import TweepyException\n",
    "\n",
    "def fetch_user_tweets(client, user_id, max_results, start_time, end_time):\n",
    "    try:\n",
    "        response = client.get_users_tweets(\n",
    "            id=user_id,\n",
    "            max_results=max_results,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            tweet_fields=[\"created_at\", \"text\", \"id\", \"author_id\", \"public_metrics\"]\n",
    "        )\n",
    "        return response.data\n",
    "    except TweepyException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_tweets_to_json(tweets, filename=\"tweets.json\"):\n",
    "    try:\n",
    "        # Load existing data, if the file exists\n",
    "        try:\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "                existing_data = json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            existing_data = []\n",
    "\n",
    "        # Find the latest existing tweet by date\n",
    "        existing_tweet_ids = {tweet[\"id\"] for tweet in existing_data}\n",
    "        new_tweets = [\n",
    "            {\n",
    "                \"id\": tweet.id,\n",
    "                \"created_at\": tweet.created_at.isoformat(),\n",
    "                \"text\": tweet.text,\n",
    "                \"author_id\": tweet.author_id,\n",
    "                \"public_metrics\": tweet.public_metrics\n",
    "            }\n",
    "            for tweet in tweets if tweet.id not in existing_tweet_ids\n",
    "        ]\n",
    "        \n",
    "        # Append new tweets only if they're not duplicates\n",
    "        if new_tweets:\n",
    "            existing_data.extend(new_tweets)\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(existing_data, file, ensure_ascii=False, indent=4)\n",
    "            print(f\"Appended {len(new_tweets)} new tweets to {filename}\")\n",
    "        else:\n",
    "            print(\"No new tweets to save.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving tweets: {e}\")\n",
    "\n",
    "# Example usage\n",
    "tweets = fetch_user_tweets(client, user_id, max_results=100, start_time=start_time, end_time=end_time)\n",
    "save_tweets_to_json(tweets, filename=\"tweets.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tweet id=1720892929512988968 text='Nie dzwoń już więcej, Mateusz. Mamy komplet ministrów.'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing new\n",
    "# Parameters\n",
    "user_id = \"375146901\"  # Replace with the desired user's ID\n",
    "max_results = 100  # Number of tweets per page (between 5 and 100)\n",
    "start_time = \"2024-10-29T00:00:00Z\"  # Replace with your start date/time\n",
    "end_time = \"2024-11-07T00:00:00Z\"    # Replace with your end date/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tweepy import TweepyException\n",
    "\n",
    "def fetch_user_tweets(client, user_id, max_results, start_time, end_time):\n",
    "    try:\n",
    "        response = client.get_users_tweets(\n",
    "            id=user_id,\n",
    "            max_results=max_results,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            tweet_fields=[\n",
    "                \"created_at\", \"text\", \"id\", \"author_id\", \"public_metrics\", \n",
    "                \"context_annotations\", \"entities\", \"in_reply_to_user_id\",\n",
    "                \"attachments\", \"geo\", \"lang\", \"source\", \"possibly_sensitive\",\n",
    "                \"reply_settings\", \"referenced_tweets\"\n",
    "            ]\n",
    "        )\n",
    "        return response.data\n",
    "    except TweepyException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_tweets_to_json(tweets, filename=\"tweets.json\"):\n",
    "    try:\n",
    "        # Load existing data, if the file exists\n",
    "        try:\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "                existing_data = json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            existing_data = []\n",
    "\n",
    "        # Find the latest existing tweet by date\n",
    "        existing_tweet_ids = {tweet[\"id\"] for tweet in existing_data}\n",
    "        new_tweets = [\n",
    "            {\n",
    "                \"id\": tweet.id,\n",
    "                \"created_at\": tweet.created_at.isoformat(),\n",
    "                \"text\": tweet.text,\n",
    "                \"author_id\": tweet.author_id,\n",
    "                \"public_metrics\": tweet.public_metrics,\n",
    "                \"context_annotations\": tweet.context_annotations,\n",
    "                \"entities\": tweet.entities,\n",
    "                \"in_reply_to_user_id\": tweet.in_reply_to_user_id,\n",
    "                \"attachments\": tweet.attachments,\n",
    "                \"geo\": tweet.geo,\n",
    "                \"lang\": tweet.lang,\n",
    "                \"source\": tweet.source,\n",
    "                \"possibly_sensitive\": tweet.possibly_sensitive,\n",
    "                \"reply_settings\": tweet.reply_settings,\n",
    "                \"referenced_tweets\": tweet.referenced_tweets\n",
    "            }\n",
    "            for tweet in tweets if tweet.id not in existing_tweet_ids\n",
    "        ]\n",
    "        \n",
    "        # Append new tweets only if they're not duplicates\n",
    "        if new_tweets:\n",
    "            existing_data.extend(new_tweets)\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(existing_data, file, ensure_ascii=False, indent=4)\n",
    "            print(f\"Appended {len(new_tweets)} new tweets to {filename}\")\n",
    "        else:\n",
    "            print(\"No new tweets to save.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving tweets: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429 Too Many Requests\n",
      "Too Many Requests\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "tweets = fetch_user_tweets(client, user_id, max_results=100, start_time=start_time, end_time=end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving tweets: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "save_tweets_to_json(tweets, filename=\"tweets.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
